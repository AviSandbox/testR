install.packages(c('cluster'),'fpc','arules'))
library(cluster)
library(fpc)
libary(arules)
install.packages(c('cluster'),'fpc','arules'))
library(cluster)
library(fpc)
library(arules)
install.packages(c('cluster'),'fpc','arules'))
install.packages(c('cluster','fpc','arules'))
install.packages(c("cluster", "fpc", "arules"))
library(cluster)
library(fpc)
library(arules)
library(cluster)
library(fpc)
library(arules)
set.seed(5)
library(readxl)
Cluster_data <- read_excel("~/Downloads/Cluster_data.xlsx")
View(Cluster_data)
x<-matrix(rnorm(300),150,2)
View(Cluster_data)
View(x)
xmean<-matrix(rnorm(8),4,2)
View(xmean)
which<-sample(1:4, 150, replace=T)
x<-x+xmean[which,]
plot(x,col=which, pch=19)
shiny::runApp('lab2')
x.cluster<-cbind(x, which)
while(TRUE){
centroid<-c()
for (g in 1:4)
centroid <-matrix(centroid, 4,2, byrow=T)
distance <-c()
for (i in 1:nrow(x){
for (j in 1:4){
dis<-sqrt(sum((x[i,]-centroid[j,])^2))
distance <-c(distance, dis)
}
})
}
x.cluster<-cbind(x, which)
while(TRUE){
centroid<-c()
for (g in 1:4)
centroid<-c(centroid,mean(x.cluster[x.cluster[,3]==g,l]),
mean(x.cluster[x.cluster[,3]==g,2]))
}
x.cluster<-cbind(x, which)
while(TRUE){
centroid<-c()
for (g in 1:4)
centroid<-c(centroid,mean(x.cluster[x.cluster[,3]==g,1]),
mean(x.cluster[x.cluster[,3]==g,2]))
}
while(TRUE){
centroid<-c()
for (g in 1:4)
centroid<-c(centroid,mean(x.cluster[x.cluster[,3]==g,1]),
mean(x.cluster[x.cluster[,3]==g,2]))
}
x<-matrix(rnorm(300),150,2)
xmean<-matrix(rnorm(8),4,2)# check
which<-sample(1:4, 150, replace=T)
x<-x+xmean[which,]
plot(x,col=which, pch=19)
x.cluster<-cbind(x, which)
while(TRUE){
centroid<-c()
for (g in 1:4)
centroid<-c(centroid,mean(x.cluster[x.cluster[,3]==g,1]),
mean(x.cluster[x.cluster[,3]==g,2]))
}
while(TRUE){
centroid<-c()
for (g in 1:4)
centroid<-c(centroid,mean(x.cluster[x.cluster[,3]==g,1]),
mean(x.cluster[x.cluster[,3]==g,2]))
}
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
install.packages(c('cluster'))
library(fpc)
library(arules)
#####checked kmean based on lab 2########
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
cors<-cor(datanorm)
install.packages("corrplot")
library(corrplot)
corrplot(cors)
install.packages(c('cluster','fpc','arules'))
library(cluster)
install.packages(c("cluster", "fpc", "arules"))
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
cleveland <- read.csv("datasets/processed.cleveland.csv",header=T)
hungarian <- read.csv("datasets/processed.hungarian.csv",header=T)
va <- read.csv("datasets/processed.va.csv",header=T)
switzerland<- read.csv("datasets/processed.switzerland.csv",header=T)
#data <- bind_rows(cleveland, hungarian, switzerland, va)
data<-rbind(cleveland,hungarian,va,switzerland)
data$slope<-NULL
data$ca<-NULL
data$thal<-NULL
#find ? elements
idx<-data =="?"
#replace elements with NA
is.na(data) <- idx
for(i in 1:ncol(data)){ #for every column of our data
data[is.na(data[,i]), i] <- mean(as.numeric(data[,i]), na.rm =
TRUE) #replace every missing values with the mean of that column
}
data[] <- lapply(data, as.integer)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
#Activity 1: K-means
install.packages(c('cluster','fpc','arules'))
library(cluster)
library(fpc)
library(arules)
# The need is the possible desire for reproducible results,
# which may for example come from trying to debug your program
#we set a random seed to allow us to reproduce the same results
set.seed(5)
?set.seed
#The dataset contains 150 observations, each of which is described by a two-element
#vector drawn from the normal distribution
x<-matrix(rnorm(300),150,2)
#Generate a deviation matrix
xmean<-matrix(rnorm((8),4,2))
xmean
which<-sample(1:4, 150,replace=T)
x
x<-x+xmean[which,]
plot(x, col=which, pch=21)
x.cluster<-cbind(x,which)
x.cluster
while(TRUE){
centroid<-c()
for(g in 1:4){
centroid<-c(centroid, mean(x.cluster[x.cluster[,3]==g,1]),mean(x.cluster[x.cluster[,3]==g,2]))
}
centroid<-matrix(centroid,4,2,byrow=T)
distance<-c()
for(i in 1:nrow(x)){
for(j in 1:4){
dis<-sqrt(sum((x[i,]-centroid[j,])^2))
distance<-c(distance,dis)
}
}
distance<-matrix(distance,150,4,byrow=T)
centroid.label<-apply(distance,1,which.min)
if(all(centroid.label==x.cluster[,3])){
km.clusters<-centroid.label
centroid.matrix<-centroid
break
}else{
x.cluster[,3]<-centroid.label
}
}
plot(x, col=centroid.label, pch=19)
points(centroid, pch=19, col=6, cex=2)
# alternatives
set.seed(5)
km.out<-kmeans(x,2)
km.out
plot(x,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
#optimal nubmer of clusters
pamk.best<-pamk(x)
cat("number of clsters according to optimum average silhouette width(best seperated clusters):",pamk.best$nc,"\n")
plot(pam(x,pamk.best$nc))
library(corrplot)
corrplot(cors)
install.packages(c('cluster','fpc','arules'))
library(cluster)
library(fpc)
library(arules)
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
set.seed(5)
km.out<-kmeans(x,2)
km.out
plot(x,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
pamk.best<-pamk(data)
cat("number of clsters according to optimum average silhouette width(best seperated clusters):",pamk.best$nc,"\n")
plot(pam(data,pamk.best$nc))
View(xmean)
View(x)
View(x.cluster)
View(xmean)
View(x.cluster)
View(x)
View(x.cluster)
View(x)
View(x.cluster)
View(x)
View(x.cluster)
View(data)
View(normalize)
cleveland <- read.csv("datasets/processed.cleveland.csv",header=T)
hungarian <- read.csv("datasets/processed.hungarian.csv",header=T)
va <- read.csv("datasets/processed.va.csv",header=T)
switzerland<- read.csv("datasets/processed.switzerland.csv",header=T)
#data <- bind_rows(cleveland, hungarian, switzerland, va)
data<-rbind(cleveland,hungarian,va,switzerland)
data$slope<-NULL
data$ca<-NULL
data$thal<-NULL
#find ? elements
idx<-data =="?"
#replace elements with NA
is.na(data) <- idx
for(i in 1:ncol(data)){ #for every column of our data
data[is.na(data[,i]), i] <- mean(as.numeric(data[,i]), na.rm =
TRUE) #replace every missing values with the mean of that column
}
data[] <- lapply(data, as.integer)
cleveland <- read.csv("datasets/processed.cleveland.csv",header=T)
hungarian <- read.csv("datasets/processed.hungarian.csv",header=T)
va <- read.csv("datasets/processed.va.csv",header=T)
switzerland<- read.csv("datasets/processed.switzerland.csv",header=T)
#data <- bind_rows(cleveland, hungarian, switzerland, va)
data<-rbind(cleveland,hungarian,va,switzerland)
data$slope<-NULL
data$ca<-NULL
data$thal<-NULL
#find ? elements
idx<-data =="?"
#replace elements with NA
is.na(data) <- idx
for(i in 1:ncol(data)){ #for every column of our data
data[is.na(data[,i]), i] <- mean(as.numeric(data[,i]), na.rm =
TRUE) #replace every missing values with the mean of that column
}
data[] <- lapply(data, as.integer)
cleveland <- read.csv("datasets/processed.cleveland.csv",header=T)
hungarian <- read.csv("datasets/processed.hungarian.csv",header=T)
va <- read.csv("datasets/processed.va.csv",header=T)
switzerland<- read.csv("datasets/processed.switzerland.csv",header=T)
#data <- bind_rows(cleveland, hungarian, switzerland, va)
data<-rbind(cleveland,hungarian,va,switzerland)
data$slope<-NULL
data$ca<-NULL
data$thal<-NULL
#find ? elements
idx<-data =="?"
#replace elements with NA
is.na(data) <- idx
for(i in 1:ncol(data)){ #for every column of our data
data[is.na(data[,i]), i] <- mean(as.numeric(data[,i]), na.rm =
TRUE) #replace every missing values with the mean of that column
}
data[] <- lapply(data, as.integer)
setwd("~/Desktop/triple")
cleveland <- read.csv("datasets/processed.cleveland.csv",header=T)
cleveland <- read.csv("datasets/processed.cleveland.csv",header=T)
hungarian <- read.csv("datasets/processed.hungarian.csv",header=T)
va <- read.csv("datasets/processed.va.csv",header=T)
switzerland<- read.csv("datasets/processed.switzerland.csv",header=T)
#data <- bind_rows(cleveland, hungarian, switzerland, va)
data<-rbind(cleveland,hungarian,va,switzerland)
data$slope<-NULL
data$ca<-NULL
data$thal<-NULL
#find ? elements
idx<-data =="?"
#replace elements with NA
is.na(data) <- idx
for(i in 1:ncol(data)){ #for every column of our data
data[is.na(data[,i]), i] <- mean(as.numeric(data[,i]), na.rm =
TRUE) #replace every missing values with the mean of that column
}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
data[] <- lapply(data, as.integer)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
datanorm <- as.data.frame(lapply(data, normalize))
View(datanorm)
set.seed(5)
km.out<-kmeans(data,5)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
install.packages(c('cluster'))
library(cluster)
pamk.best<-pamk(data)
cat("number of clsters according to optimum average silhouette width(best seperated clusters):",pamk.best$nc,"\n")
plot(pam(data,pamk.best$nc))
km.out<-kmeans(data,2)
km.out
plot(data,col=km.out$cluster, pch=19)
points(km.out$centers, pch=19, col=6,cex=2)
#optimal nubmer of clusters
install.packages(c('cluster'))
library(cluster)
pamk.best<-pamk(data)
cat("number of clsters according to optimum average silhouette width(best seperated clusters):",pamk.best$nc,"\n")
plot(pam(data,pamk.best$nc))
